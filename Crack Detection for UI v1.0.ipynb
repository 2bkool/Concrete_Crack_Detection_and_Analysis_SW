{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted boxes:\n",
      "\n",
      "   class   conf xmin   ymin   xmax   ymax\n",
      "frame : 0\n",
      "frame : 5\n",
      "frame : 10\n",
      "frame : 15\n",
      "frame : 20\n",
      "frame : 25\n",
      "frame : 30\n",
      "frame : 35\n",
      "frame : 40\n",
      "frame : 45\n",
      "frame : 50\n",
      "frame : 55\n",
      "frame : 60\n",
      "frame : 65\n",
      "frame : 70\n",
      "frame : 75\n",
      "frame : 80\n",
      "frame : 85\n",
      "frame : 90\n",
      "frame : 95\n",
      "frame : 100\n",
      "xmin :  -3.7950758934020996   ymin :  11.739411900838217   xmax :  841.7351481119791   ymax :  216.10314778645832\n",
      "frame : 105\n",
      "frame : 110\n",
      "frame : 115\n",
      "xmin :  -9.302658081054688   ymin :  10.951525688171387   xmax :  834.99740234375   ymax :  211.03209197998046\n",
      "frame : 120\n",
      "xmin :  -7.218521931966146   ymin :  14.727643133799235   xmax :  831.1311800130209   ymax :  208.32061381022135\n",
      "frame : 125\n",
      "frame : 130\n",
      "xmin :  0.18059635162353516   ymin :  14.443070087432861   xmax :  834.390283203125   ymax :  197.7364427693685\n",
      "frame : 135\n",
      "frame : 140\n",
      "frame : 145\n",
      "xmin :  -0.3447403907775879   ymin :  18.943992462158203   xmax :  834.871630859375   ymax :  201.02261678059895\n",
      "frame : 150\n",
      "xmin :  3.0437536239624023   ymin :  21.081617577870688   xmax :  840.377626953125   ymax :  204.97622680664062\n",
      "frame : 155\n",
      "xmin :  2.5439672470092773   ymin :  21.03598444620768   xmax :  838.7129231770833   ymax :  205.1082437133789\n",
      "frame : 160\n",
      "xmin :  12.842179438273112   ymin :  23.701872075398764   xmax :  842.92462890625   ymax :  208.56263448079426\n",
      "frame : 165\n",
      "xmin :  8.519087931315104   ymin :  16.32816743850708   xmax :  839.473935546875   ymax :  198.89403259277344\n",
      "frame : 170\n",
      "xmin :  -0.19447088241577148   ymin :  21.30272860209147   xmax :  832.1697867838542   ymax :  201.41939025878906\n",
      "frame : 175\n",
      "xmin :  -0.6645116806030273   ymin :  19.767664229075113   xmax :  839.6097135416667   ymax :  206.07238220214845\n",
      "frame : 180\n",
      "xmin :  0.6415643692016602   ymin :  22.6919597752889   xmax :  836.1643684895834   ymax :  208.18376475016277\n",
      "frame : 185\n",
      "xmin :  -1.1630849838256836   ymin :  16.823912296295166   xmax :  827.7479443359375   ymax :  195.66735188802085\n",
      "frame : 190\n",
      "frame : 195\n",
      "xmin :  19.19345474243164   ymin :  26.005699259440103   xmax :  831.50271484375   ymax :  209.03381072998047\n",
      "frame : 200\n",
      "frame : 205\n",
      "xmin :  -0.32419395446777344   ymin :  27.23819004058838   xmax :  838.0336881510417   ymax :  218.7347715250651\n",
      "frame : 210\n",
      "xmin :  6.939413884480794   ymin :  21.93065040588379   xmax :  845.9150227864583   ymax :  218.80564310709636\n",
      "frame : 215\n",
      "xmin :  9.48901653289795   ymin :  22.436015688578287   xmax :  848.3070963541667   ymax :  215.4624951171875\n",
      "frame : 220\n",
      "xmin :  7.934740880330404   ymin :  22.1965066019694   xmax :  846.98037109375   ymax :  214.73151835123699\n",
      "frame : 225\n",
      "xmin :  4.355743408203125   ymin :  21.39112964630127   xmax :  847.873193359375   ymax :  221.90767903645835\n",
      "frame : 230\n",
      "xmin :  1.8213038444519043   ymin :  21.551596113840738   xmax :  843.7786328125   ymax :  207.73724487304688\n",
      "frame : 235\n",
      "xmin :  7.245891571044922   ymin :  20.78861665725708   xmax :  846.9178304036458   ymax :  220.08965362548827\n",
      "frame : 240\n",
      "xmin :  11.39963259379069   ymin :  23.214493141174316   xmax :  845.7799348958333   ymax :  199.99229431152344\n",
      "frame : 245\n",
      "xmin :  10.385857442220052   ymin :  26.41082317352295   xmax :  841.6288720703125   ymax :  208.08359049479168\n",
      "frame : 250\n",
      "frame : 255\n",
      "frame : 260\n",
      "frame : 265\n",
      "frame : 270\n",
      "frame : 275\n",
      "frame : 280\n",
      "frame : 285\n",
      "frame : 290\n",
      "xmin :  50.25951548258463   ymin :  34.71217863718669   xmax :  861.3557584635416   ymax :  779.7727587890626\n",
      "frame : 295\n",
      "xmin :  42.73312622070313   ymin :  35.79962996164958   xmax :  842.0287874348959   ymax :  787.7705920410157\n",
      "frame : 300\n",
      "xmin :  24.672833302815754   ymin :  42.94929640452067   xmax :  804.8025846354167   ymax :  791.1646634928385\n",
      "frame : 305\n",
      "xmin :  11.025803705851237   ymin :  44.44709615071615   xmax :  789.4067919921876   ymax :  794.8235534667969\n",
      "frame : 310\n",
      "xmin :  9.689628601074219   ymin :  39.96738543192546   xmax :  779.218525390625   ymax :  800.1968253580729\n",
      "frame : 315\n",
      "xmin :  8.764811515808105   ymin :  41.21121576944987   xmax :  762.6291975911458   ymax :  794.2475773111979\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, 3),\n",
    "                n_classes=1,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], \n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=[8, 16, 32, 64, 100, 300],\n",
    "                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                clip_boxes=False,\n",
    "                variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                normalize_coords=True,\n",
    "                subtract_mean=[123, 117, 104],\n",
    "                swap_channels=[2, 1, 0],\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400)\n",
    "\n",
    "#학습된 weight의 경로를 지정\n",
    "weights_path = 'ssd300_pascal_07+12_epoch-04_loss-3.0387_val_loss-3.5244_weight.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)\n",
    "#영상의 경로를 지정하고 프레임 캡쳐\n",
    "vidcap = cv2.VideoCapture('C:\\\\Users\\\\user\\Desktop\\\\video.mp4')\n",
    "success,imagefile = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    if(count%5==0):\n",
    "#프레임 캡쳐를 저장할 경로\n",
    "        cv2.imwrite(\"C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg\" % count, imagefile)    \n",
    "    success,imagefile = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "orig_images = [] \n",
    "input_images = [] \n",
    "\n",
    "for i in range(0,320):\n",
    "    if(i%5==0):\n",
    "#프레임 캡쳐를 저장하는 경로\n",
    "        img_path = 'C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg'%i\n",
    "        #print(img_path)\n",
    "        orig_images.append(imread(img_path))\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img)\n",
    "        input_images.append(img)\n",
    "        \n",
    "input_images = np.array(input_images)\n",
    "\n",
    "num_of_frames = 16\n",
    "counting = 0\n",
    "\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "    \n",
    "for i in range(0, int(len(input_images)/num_of_frames)):\n",
    "    y_pred = model.predict(input_images[i*num_of_frames:i*num_of_frames + num_of_frames])\n",
    "    confidence_threshold = 0.4\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "    for j in range(0, num_of_frames):\n",
    "        print('frame :',counting)\n",
    "        counting += 5\n",
    "#        print(y_pred_thresh[j])\n",
    "        for box in y_pred_thresh[j]:\n",
    "            # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "            xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "            ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "            xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "            ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "            print('xmin : ',xmin, '  ymin : ',ymin, '  xmax : ',xmax, '  ymax : ',ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
