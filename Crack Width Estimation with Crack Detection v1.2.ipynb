{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rlaal\\Anaconda3\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "import os\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, 3),\n",
    "                n_classes=1,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], \n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=[8, 16, 32, 64, 100, 300],\n",
    "                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                clip_boxes=False,\n",
    "                variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                normalize_coords=True,\n",
    "                subtract_mean=[123, 117, 104],\n",
    "                swap_channels=[2, 1, 0],\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400)\n",
    "\n",
    "#학습된 weight의 경로를 지정\n",
    "# ----------------------------\n",
    "weights_path = '/usr/local/lib/python3.5/dist-packages/tensorflow/keras/ssd_keras/ssd300_pascal_07+12_epoch-04_loss-3.0387_val_loss-3.5244_weight.h5'\n",
    "# weights_path = 'C:\\Users\\rlaal\\Desktop\\ssd300_pascal_07+12_epoch-04_loss-3.0387_val_loss-3.5244_weight.h5'\n",
    "# ----------------------------done\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted boxes:\n",
      "\n",
      "   class   conf xmin   ymin   xmax   ymax\n",
      "frame : 0\n",
      "frame : 6\n",
      "frame : 12\n",
      "frame : 18\n",
      "frame : 24\n",
      "frame : 30\n",
      "xmin :  -4.623878479003906   ymin :  5.771284103393555   xmax :  1314.4258357747397   ymax :  106.45499267578126\n",
      "frame : 36\n",
      "frame : 42\n",
      "frame : 48\n",
      "xmin :  5.500088930130005   ymin :  7.980387115478516   xmax :  1317.9852709960937   ymax :  105.38902587890625\n",
      "frame : 54\n",
      "xmin :  9.43581509590149   ymin :  9.405484008789063   xmax :  1325.0742415364584   ymax :  108.44346923828125\n",
      "frame : 60\n",
      "xmin :  -0.9292029142379761   ymin :  11.69836883544922   xmax :  1319.1835567220053   ymax :  111.84700927734374\n",
      "frame : 66\n",
      "xmin :  -1.1444872617721558   ymin :  9.378490447998047   xmax :  1323.1917598470052   ymax :  108.6945068359375\n",
      "frame : 72\n",
      "xmin :  3.209930658340454   ymin :  11.124665832519531   xmax :  1321.723701578776   ymax :  109.18963623046875\n",
      "frame : 78\n",
      "xmin :  6.327015995979309   ymin :  9.764395904541015   xmax :  1324.04835164388   ymax :  106.647900390625\n",
      "frame : 84\n",
      "frame : 90\n",
      "frame : 96\n",
      "frame : 102\n",
      "frame : 108\n",
      "frame : 114\n",
      "frame : 120\n",
      "frame : 126\n",
      "frame : 132\n",
      "frame : 138\n",
      "frame : 144\n",
      "frame : 150\n",
      "frame : 156\n",
      "frame : 162\n",
      "frame : 168\n",
      "frame : 174\n",
      "frame : 180\n",
      "frame : 186\n",
      "frame : 192\n",
      "frame : 198\n",
      "frame : 204\n",
      "frame : 210\n",
      "frame : 216\n",
      "frame : 222\n",
      "frame : 228\n",
      "frame : 234\n",
      "frame : 240\n",
      "frame : 246\n",
      "frame : 252\n",
      "frame : 258\n",
      "frame : 264\n",
      "frame : 270\n",
      "frame : 276\n",
      "frame : 282\n",
      "frame : 288\n",
      "frame : 294\n",
      "frame : 300\n",
      "frame : 306\n",
      "frame : 312\n",
      "frame : 318\n",
      "[[30, -4.623878479003906, 5.771284103393555, 1314.4258357747397, 106.45499267578126], [48, 5.500088930130005, 7.980387115478516, 1317.9852709960937, 105.38902587890625], [54, 9.43581509590149, 9.405484008789063, 1325.0742415364584, 108.44346923828125], [60, -0.9292029142379761, 11.69836883544922, 1319.1835567220053, 111.84700927734374], [66, -1.1444872617721558, 9.378490447998047, 1323.1917598470052, 108.6945068359375], [72, 3.209930658340454, 11.124665832519531, 1321.723701578776, 109.18963623046875], [78, 6.327015995979309, 9.764395904541015, 1324.04835164388, 106.647900390625]]\n"
     ]
    }
   ],
   "source": [
    "#영상의 경로를 지정하고 프레임 캡쳐\n",
    "#나중에는 비디오 캡쳐를 함과 동시에 input_images리스트에 곧바로 넣어버려서, 불필요한 이미지 입출력 과정을 줄이자\n",
    "#1초에 4프레임 캡쳐로 바꿈 (6프레임마다 저장)\n",
    "\n",
    "# from wand.drawing import Drawing\n",
    "# from wand.image import Image\n",
    "# from wand.color import Color\n",
    "# import os\n",
    "\n",
    "# We will get video name from node.js server this is demo version\n",
    "\n",
    "# --------------------\n",
    "vidcap = cv2.VideoCapture('UI\\\\video.mp4')\n",
    "# vidcap = cv2.VideoCapture('C:\\\\Users\\\\rlaal\\\\Desktop\\\\video.mp4')\n",
    "# -----------------done\n",
    "success,imagefile = vidcap.read()\n",
    "count = 0\n",
    "\n",
    "# -----------------make directory\n",
    "newimagepath = \"images\\\\video\"\n",
    "\n",
    "if not os.path.exists(newimagepath):\n",
    "    os.makedirs(newimagepath)\n",
    "newframepath = \"images\\\\video_crack\"\n",
    "\n",
    "if not os.path.exists(newframepath):\n",
    "    os.makedirs(newframepath)\n",
    "    \n",
    "newinfopath = \"images\\\\video_info\"\n",
    "\n",
    "if not os.path.exists(newinfopath):\n",
    "    os.makedirs(newinfopath)\n",
    "# ----------------done\n",
    "\n",
    "while success:\n",
    "    \n",
    "    if(count%6==0):\n",
    "#프레임 캡쳐를 저장할 경로\n",
    "        # --------------------\n",
    "        imagepath = \"images\\\\video\\\\%d.jpg\"% count, imagefile\n",
    "        cv2.imwrite(imagepath )\n",
    "        # cv2.imwrite(\"C:\\\\Users\\\\rlaal\\\\Desktop\\\\frame\\\\frame%d.jpg\"% count, imagefile)\n",
    "        # -------------------done\n",
    "    success,imagefile = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "orig_images = [] \n",
    "input_images = [] \n",
    "\n",
    "# range는 추후 영상 플레이 타임 정보를 사용할 수 있도록 변경\n",
    "for i in range(0,320):\n",
    "    if(i%6==0):\n",
    "#프레임 캡쳐를 불러오는 경로\n",
    "        # ---------------------------\n",
    "        img_path = 'images\\\\video\\\\%d.jpg'%i\n",
    "        # img_path = 'C:\\\\Users\\\\rlaal\\\\Desktop\\\\frame\\\\frame%d.jpg'%i\n",
    "        # ----------------------------done\n",
    "        #print(img_path)\n",
    "        orig_images.append(imread(img_path))\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img)\n",
    "        input_images.append(img)\n",
    "        \n",
    "input_images = np.array(input_images)\n",
    "orig_images = np.array(orig_images)\n",
    "\n",
    "num_of_frames = 16\n",
    "counting = 0\n",
    "saving_bounding_boxes = []\n",
    "\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "\n",
    "# range는 추후 변수를 사용할 수 있도록 변경\n",
    "for i in range(0, 4):\n",
    "    y_pred = model.predict(input_images[i*num_of_frames:i*num_of_frames + num_of_frames])\n",
    "    confidence_threshold = 0.4\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "    for j in range(0, num_of_frames):\n",
    "        print('frame :',counting)\n",
    "        #   print(y_pred_thresh[j])\n",
    "        for box in y_pred_thresh[j]:\n",
    "            # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "            xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "            ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "            xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "            ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "            print('xmin : ',xmin, '  ymin : ',ymin, '  xmax : ',xmax, '  ymax : ',ymax)\n",
    "            # 균열이 탐지된 프레임과 b-box 정보가 saving_bounding_boxes <- 여기에 저장됨\n",
    "            saving_bounding_boxes.append([(counting), xmin,ymin,xmax,ymax])\n",
    "            # --------------------------------------\n",
    "            framepath = \"images\\\\video_crack\\\\frame%d.jpg\"% (count), imagefile\n",
    "            cv2.imwrite(framepath)\n",
    "            # add drawing rectangle\n",
    "            #   with Drawing() as draw:\n",
    "            #       draw.stroke_width = 4.0\n",
    "            #       draw.stroke_color = Color('red')\n",
    "            #       draw.fill_color = Color('transparent')\n",
    "            #       xMin = int(xmin)\n",
    "            #       xMax = int(xmax)\n",
    "            #       yMin = int(ymin)\n",
    "            #       yMax = int(ymax)\n",
    "            #       draw.rectangle(left=xMin, top=yMin, right=xMax, bottom=yMax)\n",
    "            #       with Image(filename=\"images\\\\video_crack\\\\frame%d.jpg\"% (count)) as image:\n",
    "            #           draw(image)\n",
    "            #           boximg_path = 'images\\\\video\\\\%d.jpg'% count\n",
    "            #           image.save(filename=boximg_path)\n",
    "            # cv2.imwrite(\"C:\\\\Users\\\\rlaal\\\\Desktop\\\\detected\\\\frame%d.jpg\"% (count), imagefile)\n",
    "            # ----------------------------------------done\n",
    "            \n",
    "        counting += 6\n",
    "        if(counting>320): break;\n",
    "            \n",
    "print(saving_bounding_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0 1303 107\n",
      "../../Desktop/test/0.jpg\n",
      "26 0 1307 108\n",
      "../../Desktop/test/1.jpg\n",
      "23 0 1305 108\n",
      "../../Desktop/test/2.jpg\n",
      "28 0 1306 108\n",
      "../../Desktop/test/3.jpg\n",
      "22 0 1308 111\n",
      "../../Desktop/test/4.jpg\n",
      "26 0 1310 111\n",
      "../../Desktop/test/5.jpg\n",
      "24 0 1302 110\n",
      "../../Desktop/test/6.jpg\n",
      "27 0 1302 108\n",
      "../../Desktop/test/7.jpg\n",
      "26 0 1301 107\n",
      "../../Desktop/test/8.jpg\n",
      "23 0 1304 112\n",
      "../../Desktop/test/9.jpg\n",
      "20 0 1300 110\n",
      "../../Desktop/test/10.jpg\n",
      "22 0 1299 108\n",
      "../../Desktop/test/11.jpg\n",
      "21 0 1301 109\n",
      "../../Desktop/test/12.jpg\n",
      "23 0 1303 110\n",
      "../../Desktop/test/13.jpg\n",
      "20 0 1295 106\n",
      "../../Desktop/test/14.jpg\n",
      "8 0 1295 111\n",
      "../../Desktop/test/15.jpg\n",
      "16 0 1306 112\n",
      "../../Desktop/test/16.jpg\n",
      "13 0 1331 120\n",
      "../../Desktop/test/18.jpg\n",
      "0 2 1307 127\n",
      "../../Desktop/test/34.jpg\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "cropped_frames = []\n",
    "\n",
    "for i in range(0, len(saving_bounding_boxes)):\n",
    "    frame_count = saving_bounding_boxes[i][0]//6\n",
    "    frame = orig_images[frame_count]\n",
    "    if(saving_bounding_boxes[i][1] < 0):\n",
    "        saving_bounding_boxes[i][1] = 0\n",
    "    xmin = int(saving_bounding_boxes[i][1])\n",
    "    if(saving_bounding_boxes[i][2] < 0):\n",
    "        saving_bounding_boxes[i][2] = 0\n",
    "    ymin = int(saving_bounding_boxes[i][2])\n",
    "    xmax = int(saving_bounding_boxes[i][3])\n",
    "    ymax = int(saving_bounding_boxes[i][4])\n",
    "    print(xmin,ymin,xmax,ymax)\n",
    "    cropped_frame = orig_images[frame_count][ymin:ymax, xmin:xmax, :]\n",
    "    cropped_frame = cropped_frame.astype('uint8')\n",
    "    # -----------------------------\n",
    "    img_path = 'cropped_frames/%d.jpg'%frame_count\n",
    "    # img_path = '../../Desktop/test/%d.jpg'%frame_count\n",
    "    # -----------------------done\n",
    "    print(img_path)\n",
    "    cropped_frames.append(cropped_frame)\n",
    "    io.imsave(img_path, cropped_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\util\\arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time 1538145722.4002447\n",
      "--- 102.0319037437439 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Image binarization(Sauvola's method) using Pw and Pl, respectively\n",
    "# 오래 걸리는 문제가 있음\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import page\n",
    "from skimage.filters import (threshold_sauvola)\n",
    "from PIL import Image\n",
    "\n",
    "sauvola_frames_Pw_bw = []\n",
    "sauvola_frames_Pw = []\n",
    "\n",
    "# Upload the image\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    img = cropped_frames[i]\n",
    "    img_gray = rgb2gray(img)\n",
    "\n",
    "    # 논문에선 각각 70,180이었으나 여기선 홀수 input만 가능\n",
    "    window_size_Pw = 71\n",
    "    thresh_sauvola_Pw = threshold_sauvola(img_gray, window_size=window_size_Pw, k=0.42)\n",
    "\n",
    "    #Below are the converted images through Sauvola's method.\n",
    "    # _bw will contain 0 or 1, not true or false. bw means black or white.\n",
    "    binary_sauvola_Pw = img_gray > thresh_sauvola_Pw\n",
    "    binary_sauvola_Pw_bw = img_gray > thresh_sauvola_Pw\n",
    "\n",
    "    binary_sauvola_Pw_bw.dtype = 'uint8'\n",
    "\n",
    "    binary_sauvola_Pw_bw *= 255\n",
    "    \n",
    "    sauvola_frames_Pw_bw.append(binary_sauvola_Pw_bw)\n",
    "    sauvola_frames_Pw.append(binary_sauvola_Pw)\n",
    "    #----------------------------------------\n",
    "    img_path_Pw = 'Sauvola/Sauvola_Pw_%d.jpg'%i\n",
    "    #   img_path_Pw = '../../Desktop/Sauvola/Sauvola_Pw_%d.jpg'%i\n",
    "    #-------------------------------------------done\n",
    "    io.imsave(img_path_Pw, binary_sauvola_Pw_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_1.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_4.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_5.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_15.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_16.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_17.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_18.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract the skeletons of each images\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.util import invert\n",
    "\n",
    "skeleton_frames_Pw = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "# Invert the binarized images\n",
    "    img_Pw = invert(sauvola_frames_Pw[i])\n",
    "\n",
    "    # Below are skeletonized images\n",
    "    skeleton_Pw = skeletonize(img_Pw)\n",
    "\n",
    "    # Convert true/false to 1/0 to save it as image\n",
    "    skeleton_Pw.dtype = 'uint8'\n",
    "\n",
    "    skeleton_Pw *= 255\n",
    "\n",
    "    skeleton_frames_Pw.append(skeleton_Pw)\n",
    "    #---------------------------\n",
    "    img_path_Pw = \"Skeleton/skeleton_Pw_%d.jpg\"%i\n",
    "    # img_path_Pw = \"../../Desktop/Skeleton/skeleton_Pw_%d.jpg\"%i\n",
    "    #---------------------------done\n",
    "    io.imsave(img_path_Pw, skeleton_Pw)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Detect the edges of each images\n",
    "### edge detection 할 때, 좋은 parameter를 찾아야 한다. 지금은 edge가 너무 두꺼움 (overestimation됨) ###\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "\n",
    "edges_frames_Pw = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    # Compute the Canny filter for two values of sigma\n",
    "    # canny(image, sigma=1.0, low_threshold=None, high_threshold=None, mask=None, use_quantiles=False)\n",
    "    # sigma가 1이었으나, 0.1로 조정하여 실제 균열 edge와 거의 같게 만듦.\n",
    "    # 정확도에서 문제가 생긴다면 1. skeleton의 방향 설정 방법을 바꾸던가, 2. 여기서 시그마 값을 살짝 늘리거나 줄여가면서 정확도를 테스트 해볼 것\n",
    "    edges_Pw = feature.canny(sauvola_frames_Pw[i], 0.09)\n",
    "\n",
    "    edges_Pw.dtype = 'uint8'\n",
    "\n",
    "    edges_Pw *= 255\n",
    "\n",
    "    edges_frames_Pw.append(edges_Pw)\n",
    "    #----------------------------\n",
    "    img_path_Pw = \"edges/edges_Pw_%d.jpg\"%i\n",
    "    # img_path_Pw = \"../../Desktop/edges/edges_Pw_%d.jpg\"%i\n",
    "    #----------------------------done\n",
    "    io.imsave(img_path_Pw, edges_Pw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 1276)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 107 is out of bounds for axis 0 with size 107",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-b3022f650fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m146\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeleton_frames_Pw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_skeleton\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_skeleton\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 107 is out of bounds for axis 0 with size 107"
     ],
     "output_type": "error"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Crack만이 detection되어서 넘어왔다는 가정이 있어야 함. 아니면 외부 배경 이미지도 균열 계산에 포함 됨\n",
    "\n",
    "import queue\n",
    "import math\n",
    "\n",
    "#5픽셀이 기준 or above\n",
    "dx_dir_right = [-5,-5,-5,-4,-3,-2,-1,0,1,2,3,4,5,5]\n",
    "dy_dir_right = [0,1,2,3,4,5,5,5,5,5,4,3,2,1]\n",
    "\n",
    "dx_dir_left = [5,5,5,4,3,2,1,0,-1,-2,-3,-4,-5,-5]\n",
    "dy_dir_left = [0,-1,-2,-3,-4,-5,-5,-5,-5,-5,-4,-3,-2,-1]\n",
    "\n",
    "dx_bfs = [-1,-1,0,1,1,1,0,-1]\n",
    "dy_bfs = [0,1,1,1,0,-1,-1,-1]\n",
    "\n",
    "\n",
    "for k in range(0,len(skeleton_frames_Pw)):\n",
    "    print('--------------',k,'-----------------')\n",
    "    start = [0,0]\n",
    "    next = []\n",
    "    q = queue.Queue()\n",
    "    q.put(start)\n",
    "\n",
    "    len_x = skeleton_frames_Pw[k].shape[0]\n",
    "    len_y = skeleton_frames_Pw[k].shape[1]\n",
    "\n",
    "    visit = np.zeros((len_x,len_y))\n",
    "    count = 0\n",
    "    crack_width_list = []\n",
    "\n",
    "    while(q.empty() == 0):\n",
    "        next = q.get()\n",
    "        x = next[0]\n",
    "        y = next[1]\n",
    "        right_x = right_y = left_x = left_y = -1\n",
    "\n",
    "\n",
    "        if(skeleton_frames_Pw[k][x][y] == 255):\n",
    "            for i in range(0, len(dx_dir_right)):\n",
    "                right_x = x + dx_dir_right[i]\n",
    "                right_y = y + dy_dir_right[i]\n",
    "                if(right_x<0 or right_y<0 or right_x>=len_x or right_y>=len_y): \n",
    "                    right_x = right_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][right_x][right_y] == 255): break;\n",
    "                if(i==13): right_x = right_y = -1\n",
    "\n",
    "            if(right_x == -1): \n",
    "                right_x = x\n",
    "                right_y = y\n",
    "\n",
    "            for i in range(0, len(dx_dir_left)):\n",
    "                left_x = x + dx_dir_left[i]\n",
    "                left_y = y + dy_dir_left[i]\n",
    "                if(left_x <0 or left_y<0 or left_x >=len_x or left_y>=len_y): \n",
    "                    left_x = left_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][left_x][left_y] == 255): break;\n",
    "                if(i==13): left_x = left_y = -1\n",
    "\n",
    "            if(left_x == -1): \n",
    "                left_x = x\n",
    "                left_y = y\n",
    "\n",
    "            base = right_y - left_y\n",
    "            height = right_x - left_x\n",
    "            hypotenuse = math.sqrt(base*base + height*height)\n",
    "\n",
    "            if(base==0 and height != 0): theta = 90.0\n",
    "            elif(base==0 and height == 0): continue\n",
    "            else: theta = math.degrees(math.acos((base * base + hypotenuse * hypotenuse - height * height)/(2.0 * base * hypotenuse)))\n",
    "\n",
    "\n",
    "\n",
    "            theta += 90\n",
    "            dist = 0\n",
    "\n",
    "            for i in range(0,2):\n",
    "\n",
    "\n",
    "                if(theta>360): theta -= 360\n",
    "                elif(theta<0): theta += 360    \n",
    "                #print(theta)\n",
    "                #print('x : ',x,'y : ',y)\n",
    "                pix_x=x\n",
    "                pix_y=y\n",
    "\n",
    "                #theta에러는 나중에 고치고\n",
    "                #모든 프레임을 처리하기 위한 루프 먼저 돌릴것\n",
    "                #결과 값을 UI와 연동하자\n",
    "\n",
    "                if(theta>0 and theta<90):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((x - pix_x + 1)/(pix_y - y + 1)> ratio): pix_y+=1\n",
    "                        else: pix_x-=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta>90 and theta<180):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((x - pix_x + 1)/(y - pix_y + 1)> ratio): pix_y-=1\n",
    "                        else: pix_x-=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta>180 and theta<270):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((pix_x - x + 1)/(y - pix_y+ 1)> ratio): pix_y-=1\n",
    "                        else: pix_x+=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;     \n",
    "\n",
    "                elif(theta>270 and theta<360):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((pix_x - x + 1)/(pix_y - y + 1)> ratio): pix_y+=1\n",
    "                        else: pix_x+=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 0.0 or 360.0):\n",
    "                     while(1):\n",
    "                        pix_y+=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 90.0):\n",
    "                    while(1):\n",
    "                        pix_x-=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 180.0):\n",
    "                    while(1):\n",
    "                        pix_y-=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 270.0):\n",
    "                     while(1):\n",
    "                        pix_x+=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;            \n",
    "\n",
    "                dist += math.sqrt((y-pix_y)**2 + (x-pix_x)**2)\n",
    "                theta += 180        \n",
    "\n",
    "                #print('pix_x : ',pix_x,'pix_y : ',pix_y,'dist : ', dist,'\\n')\n",
    "\n",
    "            crack_width_list.append(dist)\n",
    "        \n",
    "            #해당 위치와 균열 폭을 힘께 저장하는 새로운 리스트 사용하기\n",
    "        for i in range(0,8):\n",
    "            next_x = x + dx_bfs[i]\n",
    "            next_y = y + dy_bfs[i]\n",
    "\n",
    "            if(next_x<0 or next_y<0 or next_x>=len_x or next_y>=len_y): continue;\n",
    "            if(visit[next_x][next_y] == 0): \n",
    "                q.put([next_x,next_y])\n",
    "                visit[next_x][next_y] = 1\n",
    "        \n",
    "    print(max(crack_width_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
