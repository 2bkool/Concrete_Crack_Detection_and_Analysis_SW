{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 1. 사전에 학습시킨 균열 탐지 딥러닝 weight와 Single Shot Multibox Detector model을 불러옵니다. \n",
    "\n",
    "# 1. Upload the pre-trained deep learning weight and Single Shot Multibox Detector model for crack detection.\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "# 변수 값은 Single Shot Multibox Detector의 원래 수치를 변경하지 않고 사용하였습니다.\n",
    "# The original value of parameters of 'Single Shot Multibox Detector' was used without any changes.\n",
    "model = ssd_300(image_size=(img_height, img_width, 3),\n",
    "                n_classes=2,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], \n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=[8, 16, 32, 64, 100, 300],\n",
    "                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                clip_boxes=False,\n",
    "                variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                normalize_coords=True,\n",
    "                subtract_mean=[123, 117, 104],\n",
    "                swap_channels=[2, 1, 0],\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400)\n",
    "\n",
    "# 학습된 weight를 불러오는 경로를 입력합니다.\n",
    "# Input your own path for pre-trained weight.\n",
    "weights_path = 'C:\\\\Users\\\\user\\\\keras\\\\ssd_keras\\\\ssd300_pascal_07+12_epoch-08_loss-1.9471_val_loss-1.9156.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321\n",
      "Predicted boxes:\n",
      "\n",
      "   class   conf xmin   ymin   xmax   ymax\n",
      "frame : 0\n",
      "xmin :  27.872576166788736   ymin :  -3.3622314453125   xmax :  1303.6754740397134   ymax :  107.8629150390625\n",
      "frame : 6\n",
      "xmin :  26.658366133371988   ymin :  -3.2167266845703124   xmax :  1307.7108833821615   ymax :  108.52862548828125\n",
      "frame : 12\n",
      "xmin :  23.838637828826904   ymin :  -3.223650360107422   xmax :  1305.6300118001302   ymax :  108.962451171875\n",
      "frame : 18\n",
      "xmin :  28.83223929087321   ymin :  -2.605290412902832   xmax :  1306.2607381184896   ymax :  108.52705078125\n",
      "frame : 24\n",
      "xmin :  22.28019380569458   ymin :  -2.4522186279296876   xmax :  1308.9802823893228   ymax :  111.5382568359375\n",
      "frame : 30\n",
      "xmin :  26.713252067565918   ymin :  -3.5178924560546876   xmax :  1310.0238159179687   ymax :  111.73031005859374\n",
      "frame : 36\n",
      "xmin :  24.485044339497883   ymin :  -3.776943588256836   xmax :  1302.6157784016928   ymax :  110.70706787109376\n",
      "frame : 42\n",
      "xmin :  27.910456110636392   ymin :  -4.398983764648437   xmax :  1302.6217045084636   ymax :  108.65762939453126\n",
      "frame : 48\n",
      "xmin :  26.055561542510986   ymin :  -4.845435714721679   xmax :  1301.231493733724   ymax :  107.7651611328125\n",
      "frame : 54\n",
      "xmin :  23.884251594543457   ymin :  -3.129379653930664   xmax :  1304.1557580566407   ymax :  112.13087158203125\n",
      "frame : 60\n",
      "xmin :  20.42968068440755   ymin :  -2.755726623535156   xmax :  1300.1845930989584   ymax :  110.751416015625\n",
      "frame : 66\n",
      "xmin :  22.04979746500651   ymin :  -3.682036590576172   xmax :  1299.927615559896   ymax :  108.5111572265625\n",
      "frame : 72\n",
      "xmin :  21.44501890818278   ymin :  -3.723528289794922   xmax :  1301.6298897298177   ymax :  109.236279296875\n",
      "frame : 78\n",
      "xmin :  23.99686445871989   ymin :  -2.8261398315429687   xmax :  1303.0069014485678   ymax :  110.45841064453126\n",
      "frame : 84\n",
      "xmin :  20.70261199315389   ymin :  -3.7198196411132813   xmax :  1295.7062072753906   ymax :  106.360693359375\n",
      "frame : 90\n",
      "xmin :  8.128246784210205   ymin :  -3.4087406158447267   xmax :  1295.288955485026   ymax :  111.4875732421875\n",
      "frame : 96\n",
      "xmin :  16.49138920466105   ymin :  -4.150918579101562   xmax :  1306.5672794596355   ymax :  112.6030029296875\n",
      "frame : 102\n",
      "frame : 108\n",
      "xmin :  13.459019730885824   ymin :  -0.05636930465698242   xmax :  1331.3785416666667   ymax :  120.151806640625\n",
      "frame : 114\n",
      "frame : 120\n",
      "frame : 126\n",
      "frame : 132\n",
      "frame : 138\n",
      "frame : 144\n",
      "frame : 150\n",
      "frame : 156\n",
      "frame : 162\n",
      "frame : 168\n",
      "frame : 174\n",
      "frame : 180\n",
      "frame : 186\n",
      "frame : 192\n",
      "frame : 198\n",
      "frame : 204\n",
      "xmin :  0.6658583879470825   ymin :  2.197909355163574   xmax :  1307.294305013021   ymax :  127.99669189453125\n",
      "frame : 210\n",
      "frame : 216\n",
      "frame : 222\n",
      "frame : 228\n",
      "frame : 234\n",
      "frame : 240\n",
      "frame : 246\n",
      "frame : 252\n",
      "frame : 258\n",
      "frame : 264\n",
      "frame : 270\n",
      "frame : 276\n",
      "frame : 282\n",
      "frame : 288\n",
      "frame : 294\n",
      "frame : 300\n",
      "frame : 306\n",
      "frame : 312\n",
      "frame : 318\n",
      "--- 5.320359468460083 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 2. 드론이 촬영한 콘크리트 외벽 영상에서 프레임을 추출합니다(4fps).\n",
    "#    이 프레임 이미지들을 균열 탐지 딥러닝 엔진에 입력하여 inference를 합니다.\n",
    "#    Inference의 결과 값으로 균열의 위치를 bounding box의 형태로 report합니다.\n",
    "\n",
    "# 2. Extract frames out of the video which recorded the concrete surface shoot by drone(4fps).\n",
    "#    Input the frame images into the deep learning engine for inference.\n",
    "#    The positional information will be reported as a bounding box, as a result of the inference.\n",
    "\n",
    "\n",
    "# 드론으로 촬영한 영상의 경로를 입력합니다.\n",
    "# Input the path of the video shoot by drone.\n",
    "vidcap = cv2.VideoCapture('C:\\\\Users\\\\user\\Desktop\\\\video.mp4')\n",
    "success,imagefile = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    if(count%6==0):\n",
    "# 추출된 프레임 이미지들을 저장할 경로를 입력합니다.\n",
    "# Input the path to save the extracted frame images.\n",
    "        cv2.imwrite(\"C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg\" % count, imagefile)    \n",
    "    success,imagefile = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "orig_images = [] \n",
    "input_images = [] \n",
    "\n",
    "frames_count = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(frames_count)\n",
    "for i in range(0,frames_count):\n",
    "    if(i%6==0):\n",
    "# 저장한 프레임 이미지들을 다시 불러올 수 있도록 동일한 경로를 입력합니다.\n",
    "# Input the same path used before to load the saved frame images.\n",
    "        img_path = 'C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg'%i\n",
    "        orig_images.append(imread(img_path))\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img)\n",
    "        input_images.append(img)\n",
    "        \n",
    "input_images = np.array(input_images)\n",
    "orig_images = np.array(orig_images)\n",
    "\n",
    "# 한 번에 처리되는 프레임 이미지의 갯수를 입력합니다. 보유 GPU 성능에 따라 늘리거나 줄여야 할 수 있습니다. \n",
    "# Input the number of frame images to be batch-processed.\n",
    "# You may increase or decrease the number depending on the performance of your own gpu. \n",
    "num_of_frames = 16\n",
    "counting = 0\n",
    "saving_bounding_boxes = []\n",
    "isBreak = 0;\n",
    "\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "\n",
    "for i in range(0, frames_count):\n",
    "    y_pred = model.predict(input_images[i*num_of_frames:i*num_of_frames + num_of_frames])\n",
    "    confidence_threshold = 0.4\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "    for j in range(0, num_of_frames):\n",
    "        print('frame :',counting)\n",
    "        for box in y_pred_thresh[j]:\n",
    "            xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "            ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "            xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "            ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "            print('xmin : ',xmin, '  ymin : ',ymin, '  xmax : ',xmax, '  ymax : ',ymax)\n",
    "            # 균열이 탐지된 프레임의 bounding box 위치정보를 saving_bounding_boxes 리스트에 저장합니다.\n",
    "            # Append the positional information of the bounding box of the detected frame at'saving_bounding_boxes' list.\n",
    "            saving_bounding_boxes.append([counting, xmin,ymin,xmax,ymax])\n",
    "        counting += 6\n",
    "        if(counting>frames_count): \n",
    "            isBreak = 1;\n",
    "            break;\n",
    "    if(isBreak == 1): break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0 1303 107\n",
      "26 0 1307 108\n",
      "23 0 1305 108\n",
      "28 0 1306 108\n",
      "22 0 1308 111\n",
      "26 0 1310 111\n",
      "24 0 1302 110\n",
      "27 0 1302 108\n",
      "26 0 1301 107\n",
      "23 0 1304 112\n",
      "20 0 1300 110\n",
      "22 0 1299 108\n",
      "21 0 1301 109\n",
      "23 0 1303 110\n",
      "20 0 1295 106\n",
      "8 0 1295 111\n",
      "16 0 1306 112\n",
      "13 0 1331 120\n",
      "0 2 1307 127\n",
      "--- 0.11469268798828125 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 3. 균열탐지 딥러닝 엔진이 리포트 한 균열 위치에 맞게 프레임 이미지를 잘라냅니다.\n",
    "# 3. Crop the frame image using the positional information of the crack reported by crack detection deep learning engine.\n",
    "\n",
    "from skimage import io\n",
    "\n",
    "cropped_frames = []\n",
    "\n",
    "for i in range(0, len(saving_bounding_boxes)):\n",
    "    frame_count = saving_bounding_boxes[i][0]//6\n",
    "    frame = orig_images[frame_count]\n",
    "    if(saving_bounding_boxes[i][1] < 0):\n",
    "        saving_bounding_boxes[i][1] = 0\n",
    "    xmin = int(saving_bounding_boxes[i][1])\n",
    "    if(saving_bounding_boxes[i][2] < 0):\n",
    "        saving_bounding_boxes[i][2] = 0\n",
    "    ymin = int(saving_bounding_boxes[i][2])\n",
    "    xmax = int(saving_bounding_boxes[i][3])\n",
    "    ymax = int(saving_bounding_boxes[i][4])\n",
    "    print(xmin,ymin,xmax,ymax)\n",
    "    cropped_frame = orig_images[frame_count][ymin:ymax, xmin:xmax, :]\n",
    "    cropped_frame = cropped_frame.astype('uint8')\n",
    "# 잘라낸 프레임 이미지를 저장하는 리스트입니다.\n",
    "# The list which saves the cropped frame images.\n",
    "    cropped_frames.append(cropped_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\util\\arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.704685688018799 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 4. 균열 탐지 딥러닝 엔진이 잘라낸 프레임 이미지에 전처리를 합니다.\n",
    "#    전처리는 총 3단계로 구성됩니다.\n",
    "#   1) Image Binarization : 균열인 부분과 균열이 아닌 부분을 분리합니다.\n",
    "#   2) Skeletonize : 균열의 뼈대를 추출합니다.\n",
    "#   3) Edge detection : 균열의 외곽선을 추출합니다.\n",
    "\n",
    "#   이 단계에서는 Image Binarization을 진행합니다.\n",
    "\n",
    "# 4. Preprocess the frame images cropped by crack detection deep learning engine.\n",
    "#    The preprocess consists of 3 stages.\n",
    "#   1) Image Binarization : seperate crack section and the noncrack section.\n",
    "#   2) Skeletonize : extract the central skeleton of the crack.\n",
    "#   3) Edge detection : extract the edge of the crack.\n",
    "\n",
    "#   At this stage, Image Binarization will be done.\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import page\n",
    "from skimage.filters import (threshold_sauvola)\n",
    "from PIL import Image\n",
    "\n",
    "sauvola_frames_Pw_bw = []\n",
    "sauvola_frames_Pw = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    img = cropped_frames[i]\n",
    "    img_gray = rgb2gray(img)\n",
    "\n",
    "    # window size와 k값은 'Concrete Crack Identification Using a UAV Incorporating Hybrid Image Processing' 논문이 제시한 값을\n",
    "    # 그대로 사용하였습니다.\n",
    "    \n",
    "    # window size and k value were used without any changes from the\n",
    "    # 'Concrete Crack Identification Using a UAV Incorporating Hybrid Image Processing' thesis.\n",
    "    window_size_Pw = 71\n",
    "    thresh_sauvola_Pw = threshold_sauvola(img_gray, window_size=window_size_Pw, k=0.42)\n",
    "\n",
    "    binary_sauvola_Pw = img_gray > thresh_sauvola_Pw\n",
    "    binary_sauvola_Pw_bw = img_gray > thresh_sauvola_Pw\n",
    "\n",
    "    binary_sauvola_Pw_bw.dtype = 'uint8'\n",
    "\n",
    "    binary_sauvola_Pw_bw *= 255\n",
    "    \n",
    "    # Image Binarization이 완료된 이미지를 저장하는 리스트입니다.\n",
    "    # The list which saves the images after image binarization.\n",
    "    \n",
    "    sauvola_frames_Pw_bw.append(binary_sauvola_Pw_bw)\n",
    "    sauvola_frames_Pw.append(binary_sauvola_Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.07879281044006348 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 5. 균열의 뼈대를 추출합니다.\n",
    "# 5. Extract the skeleton of the crack.\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.util import invert\n",
    "\n",
    "skeleton_frames_Pw = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    img_Pw = invert(sauvola_frames_Pw[i])\n",
    "\n",
    "    skeleton_Pw = skeletonize(img_Pw)\n",
    "\n",
    "    skeleton_Pw.dtype = 'uint8'\n",
    "\n",
    "    skeleton_Pw *= 255\n",
    "\n",
    "    # Skeletonize가 끝난 이미지를 저장하는 리스트입니다.\n",
    "    # The list which saves the images after the skeletonization.\n",
    "    skeleton_frames_Pw.append(skeleton_Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 0.5202629566192627 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 6. 균열의 외곽선을 추출합니다.\n",
    "# 6. Detect the edges of the crack.\n",
    "\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "\n",
    "edges_frames_Pw = []\n",
    "edges_frames_Pl = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    edges_Pw = feature.canny(sauvola_frames_Pw[i], 0.09)\n",
    "\n",
    "    edges_Pw.dtype = 'uint8'\n",
    "\n",
    "    edges_Pw *= 255\n",
    "    \n",
    "    # Edge detection이 끝난 이미지를 저장하는 리스트입니다.\n",
    "    # The list which saves the images after edge detection.\n",
    "    edges_frames_Pw.append(edges_Pw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------동영상 내 재생 시간 :  0.0 초 -----------------\n",
      "균열 폭 :  7.123105625617661\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  0.25 초 -----------------\n",
      "균열 폭 :  7.123105625617661\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  0.5 초 -----------------\n",
      "균열 폭 :  7.63441361516796\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  0.75 초 -----------------\n",
      "균열 폭 :  6.123105625617661\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  1.0 초 -----------------\n",
      "균열 폭 :  5.0197648378370845\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  1.25 초 -----------------\n",
      "균열 폭 :  5.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  1.5 초 -----------------\n",
      "균열 폭 :  8.261297173761164\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  1.75 초 -----------------\n",
      "균열 폭 :  33.955973405970255\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  2.0 초 -----------------\n",
      "균열 폭 :  10.373380211096357\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  2.25 초 -----------------\n",
      "균열 폭 :  10.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  2.5 초 -----------------\n",
      "균열 폭 :  10.8309518948453\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  2.75 초 -----------------\n",
      "균열 폭 :  10.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  3.0 초 -----------------\n",
      "균열 폭 :  10.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  3.25 초 -----------------\n",
      "균열 폭 :  30.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  3.5 초 -----------------\n",
      "균열 폭 :  8.625316113301073\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  3.75 초 -----------------\n",
      "균열 폭 :  7.728656901081649\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  4.0 초 -----------------\n",
      "균열 폭 :  7.0\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  4.5 초 -----------------\n",
      "균열 폭 :  9.508270432752164\n",
      "위험군 : 상 \n",
      "\n",
      "--------------동영상 내 재생 시간 :  8.5 초 -----------------\n",
      "균열 폭 :  28.021304360477224\n",
      "위험군 : 상 \n",
      "\n",
      "--- 52.28661608695984 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 7. 균열의 폭을 계산합니다. \n",
    "# 1) 균열의 Skeleton으로부터 균열의 진행 방향을 파악합니다.\n",
    "# 2) 균열의 진행 방향에 수직인 직선을 긋습니다.\n",
    "# 3) 이 수직선과 균열의 Edge가 만나는데, 이 거리가 곧 균열의 폭입니다.\n",
    "\n",
    "# 7. Calculate the width of the crack.\n",
    "# 1) Analyze the direction of the crack from the skeleton.\n",
    "# 2) Draw a perpendicular line of the direction\n",
    "# 3) The perpendicular line meets the edge. This distance is the width of the crack.\n",
    "\n",
    "import queue\n",
    "import math\n",
    "\n",
    "dx_dir_right = [-5,-5,-5,-4,-3,-2,-1,0,1,2,3,4,5,5]\n",
    "dy_dir_right = [0,1,2,3,4,5,5,5,5,5,4,3,2,1]\n",
    "\n",
    "dx_dir_left = [5,5,5,4,3,2,1,0,-1,-2,-3,-4,-5,-5]\n",
    "dy_dir_left = [0,-1,-2,-3,-4,-5,-5,-5,-5,-5,-4,-3,-2,-1]\n",
    "\n",
    "dx_bfs = [-1,-1,0,1,1,1,0,-1]\n",
    "dy_bfs = [0,1,1,1,0,-1,-1,-1]\n",
    "\n",
    "# BFS를 통해 Skeleton을 찾습니다.\n",
    "# Searching the skeleton through BFS.\n",
    "for k in range(0,len(skeleton_frames_Pw)):\n",
    "    print('--------------''동영상 내 재생 시간 : ',(saving_bounding_boxes[k][0]//6)*0.25,'초','-----------------')\n",
    "    start = [0,0]\n",
    "    next = []\n",
    "    q = queue.Queue()\n",
    "    q.put(start)\n",
    "\n",
    "    len_x = skeleton_frames_Pw[k].shape[0]\n",
    "    len_y = skeleton_frames_Pw[k].shape[1]\n",
    "\n",
    "    visit = np.zeros((len_x,len_y))\n",
    "    crack_width_list = []\n",
    "\n",
    "    while(q.empty() == 0):\n",
    "        next = q.get()\n",
    "        x = next[0]\n",
    "        y = next[1]\n",
    "        right_x = right_y = left_x = left_y = -1\n",
    "\n",
    "        if(skeleton_frames_Pw[k][x][y] == 255):\n",
    "            # Skeleton을 바탕으로 균열의 진행 방향을 구합니다.\n",
    "            # Estimating the direction of the crack from skeleton\n",
    "            for i in range(0, len(dx_dir_right)):\n",
    "                right_x = x + dx_dir_right[i]\n",
    "                right_y = y + dy_dir_right[i]\n",
    "                if(right_x<0 or right_y<0 or right_x>=len_x or right_y>=len_y): \n",
    "                    right_x = right_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][right_x][right_y] == 255): break;\n",
    "                if(i==13): right_x = right_y = -1\n",
    "\n",
    "            if(right_x == -1): \n",
    "                right_x = x\n",
    "                right_y = y\n",
    "\n",
    "            for i in range(0, len(dx_dir_left)):\n",
    "                left_x = x + dx_dir_left[i]\n",
    "                left_y = y + dy_dir_left[i]\n",
    "                if(left_x <0 or left_y<0 or left_x >=len_x or left_y>=len_y): \n",
    "                    left_x = left_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][left_x][left_y] == 255): break;\n",
    "                if(i==13): left_x = left_y = -1\n",
    "\n",
    "            if(left_x == -1): \n",
    "                left_x = x\n",
    "                left_y = y\n",
    "\n",
    "            base = right_y - left_y\n",
    "            height = right_x - left_x\n",
    "            hypotenuse = math.sqrt(base*base + height*height)\n",
    "\n",
    "            if(base==0 and height != 0): theta = 90.0\n",
    "            elif(base==0 and height == 0): continue\n",
    "            else: theta = math.degrees(math.acos((base * base + hypotenuse * hypotenuse - height * height)/(2.0 * base * hypotenuse)))\n",
    "\n",
    "            theta += 90\n",
    "            dist = 0\n",
    "            \n",
    "            # 균열 진행 방향의 수직선과 Edge가 만나면, 그 거리를 구합니다.\n",
    "            # Calculate the distance if the perpendicular line meets the edge of the crack.\n",
    "            for i in range(0,2):\n",
    "                \n",
    "                pix_x = x\n",
    "                pix_y = y\n",
    "                if(theta>360): theta -= 360\n",
    "                elif(theta<0): theta += 360    \n",
    "                \n",
    "                if(theta == 0.0 or theta == 360.0):\n",
    "                    while(1):\n",
    "                        pix_y+=1\n",
    "                        if(pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 90.0):\n",
    "                    while(1):\n",
    "                        pix_x-=1\n",
    "                        if(pix_x<0):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 180.0):\n",
    "                    while(1):\n",
    "                        pix_y-=1\n",
    "                        if(pix_y<0):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 270.0):\n",
    "                    while(1):\n",
    "                        pix_x+=1\n",
    "                        if(pix_x>=len_x):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "                else:\n",
    "                    a = 1\n",
    "                    radian = math.radians(theta)\n",
    "                    while(1):        \n",
    "                        pix_x = x - round(a*math.sin(radian))\n",
    "                        pix_y = y + round(a*math.cos(radian))\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y): \n",
    "                            pix_x=x\n",
    "                            pix_y=y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                        if(theta>0 and theta<90):\n",
    "                            if(pix_y+1<len_y and edges_frames_Pw[k][pix_x][pix_y+1]==255): \n",
    "                                pix_y+=1\n",
    "                                break;\n",
    "                            if(pix_x-1>=0 and edges_frames_Pw[k][pix_x-1][pix_y]==255): \n",
    "                                pix_x-=1\n",
    "                                break;\n",
    "\n",
    "                        elif(theta>90 and theta<180):\n",
    "                            if(pix_y-1>=0 and edges_frames_Pw[k][pix_x][pix_y-1]==255): \n",
    "                                pix_y-=1\n",
    "                                break;\n",
    "                            if(pix_x-1>=0 and edges_frames_Pw[k][pix_x-1][pix_y]==255): \n",
    "                                pix_x-=1\n",
    "                                break;\n",
    "\n",
    "                        elif(theta>180 and theta<270):\n",
    "                            if(pix_y-1>=0 and edges_frames_Pw[k][pix_x][pix_y-1]==255): \n",
    "                                pix_y-=1\n",
    "                                break;\n",
    "                            if(pix_x+1<len_x and edges_frames_Pw[k][pix_x+1][pix_y]==255): \n",
    "                                pix_x+=1\n",
    "                                break;         \n",
    "\n",
    "                        elif(theta>270 and theta<360): \n",
    "                            if(pix_y+1<len_y and edges_frames_Pw[k][pix_x][pix_y+1]==255): \n",
    "                                pix_y+=1\n",
    "                                break;\n",
    "                            if(pix_x+1<len_x and edges_frames_Pw[k][pix_x+1][pix_y]==255): \n",
    "                                pix_x+=1\n",
    "                                break;\n",
    "                        a+=1\n",
    "        \n",
    "                dist += math.sqrt((y-pix_y)**2 + (x-pix_x)**2)\n",
    "                theta += 180        \n",
    "\n",
    "            # 균열의 폭을 저장하는 리스트입니다.\n",
    "            # The list which saves the width of the crack.\n",
    "            crack_width_list.append(dist)\n",
    "        \n",
    "        for i in range(0,8):\n",
    "            next_x = x + dx_bfs[i]\n",
    "            next_y = y + dy_bfs[i]\n",
    "\n",
    "            if(next_x<0 or next_y<0 or next_x>=len_x or next_y>=len_y): continue;\n",
    "            if(visit[next_x][next_y] == 0): \n",
    "                q.put([next_x,next_y])\n",
    "                visit[next_x][next_y] = 1\n",
    "                \n",
    "    crack_width_list.sort(reverse=True)   \n",
    "    print('균열 폭 : ',crack_width_list[9])\n",
    "    print('위험군 : ','\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
