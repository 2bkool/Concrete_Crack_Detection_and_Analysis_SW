{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.optimizers import Adam\n",
    "from imageio import imread\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "from models.keras_ssd300 import ssd_300\n",
    "from keras_loss_function.keras_ssd_loss import SSDLoss\n",
    "from keras_layers.keras_layer_AnchorBoxes import AnchorBoxes\n",
    "from keras_layers.keras_layer_DecodeDetections import DecodeDetections\n",
    "from keras_layers.keras_layer_DecodeDetectionsFast import DecodeDetectionsFast\n",
    "from keras_layers.keras_layer_L2Normalization import L2Normalization\n",
    "\n",
    "from ssd_encoder_decoder.ssd_output_decoder import decode_detections, decode_detections_fast\n",
    "\n",
    "from data_generator.object_detection_2d_data_generator import DataGenerator\n",
    "from data_generator.object_detection_2d_photometric_ops import ConvertTo3Channels\n",
    "from data_generator.object_detection_2d_geometric_ops import Resize\n",
    "from data_generator.object_detection_2d_misc_utils import apply_inverse_transforms\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img_height = 300\n",
    "img_width = 300\n",
    "\n",
    "K.clear_session() \n",
    "\n",
    "model = ssd_300(image_size=(img_height, img_width, 3),\n",
    "                n_classes=2,\n",
    "                mode='inference',\n",
    "                l2_regularization=0.0005,\n",
    "                scales=[0.1, 0.2, 0.37, 0.54, 0.71, 0.88, 1.05], \n",
    "                aspect_ratios_per_layer=[[1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5, 3.0, 1.0/3.0],\n",
    "                                         [1.0, 2.0, 0.5],\n",
    "                                         [1.0, 2.0, 0.5]],\n",
    "                two_boxes_for_ar1=True,\n",
    "                steps=[8, 16, 32, 64, 100, 300],\n",
    "                offsets=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n",
    "                clip_boxes=False,\n",
    "                variances=[0.1, 0.1, 0.2, 0.2],\n",
    "                normalize_coords=True,\n",
    "                subtract_mean=[123, 117, 104],\n",
    "                swap_channels=[2, 1, 0],\n",
    "                confidence_thresh=0.5,\n",
    "                iou_threshold=0.45,\n",
    "                top_k=200,\n",
    "                nms_max_output_size=400)\n",
    "\n",
    "#학습된 weight의 경로를 지정\n",
    "weights_path = 'C:\\\\Users\\\\user\\\\keras\\\\ssd_keras\\\\ssd300_pascal_07+12_epoch-08_loss-1.9471_val_loss-1.9156.h5'\n",
    "\n",
    "model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "ssd_loss = SSDLoss(neg_pos_ratio=3, alpha=1.0)\n",
    "\n",
    "model.compile(optimizer=adam, loss=ssd_loss.compute_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted boxes:\n",
      "\n",
      "   class   conf xmin   ymin   xmax   ymax\n",
      "frame : 0\n",
      "xmin :  27.872576166788736   ymin :  -3.3622314453125   xmax :  1303.6754740397134   ymax :  107.8629150390625\n",
      "frame : 6\n",
      "xmin :  26.658366133371988   ymin :  -3.2167266845703124   xmax :  1307.7108833821615   ymax :  108.52862548828125\n",
      "frame : 12\n",
      "xmin :  23.838637828826904   ymin :  -3.223650360107422   xmax :  1305.6300118001302   ymax :  108.962451171875\n",
      "frame : 18\n",
      "xmin :  28.83223929087321   ymin :  -2.605290412902832   xmax :  1306.2607381184896   ymax :  108.52705078125\n",
      "frame : 24\n",
      "xmin :  22.28019380569458   ymin :  -2.4522186279296876   xmax :  1308.9802823893228   ymax :  111.5382568359375\n",
      "frame : 30\n",
      "xmin :  26.713252067565918   ymin :  -3.5178924560546876   xmax :  1310.0238159179687   ymax :  111.73031005859374\n",
      "frame : 36\n",
      "xmin :  24.485044339497883   ymin :  -3.776943588256836   xmax :  1302.6157784016928   ymax :  110.70706787109376\n",
      "frame : 42\n",
      "xmin :  27.910456110636392   ymin :  -4.398983764648437   xmax :  1302.6217045084636   ymax :  108.65762939453126\n",
      "frame : 48\n",
      "xmin :  26.055561542510986   ymin :  -4.845435714721679   xmax :  1301.231493733724   ymax :  107.7651611328125\n",
      "frame : 54\n",
      "xmin :  23.884251594543457   ymin :  -3.129379653930664   xmax :  1304.1557580566407   ymax :  112.13087158203125\n",
      "frame : 60\n",
      "xmin :  20.42968068440755   ymin :  -2.755726623535156   xmax :  1300.1845930989584   ymax :  110.751416015625\n",
      "frame : 66\n",
      "xmin :  22.04979746500651   ymin :  -3.682036590576172   xmax :  1299.927615559896   ymax :  108.5111572265625\n",
      "frame : 72\n",
      "xmin :  21.44501890818278   ymin :  -3.723528289794922   xmax :  1301.6298897298177   ymax :  109.236279296875\n",
      "frame : 78\n",
      "xmin :  23.99686445871989   ymin :  -2.8261398315429687   xmax :  1303.0069014485678   ymax :  110.45841064453126\n",
      "frame : 84\n",
      "xmin :  20.70261199315389   ymin :  -3.7198196411132813   xmax :  1295.7062072753906   ymax :  106.360693359375\n",
      "frame : 90\n",
      "xmin :  8.128246784210205   ymin :  -3.4087406158447267   xmax :  1295.288955485026   ymax :  111.4875732421875\n",
      "frame : 96\n",
      "xmin :  16.49138920466105   ymin :  -4.150918579101562   xmax :  1306.5672794596355   ymax :  112.6030029296875\n",
      "frame : 102\n",
      "frame : 108\n",
      "xmin :  13.459019730885824   ymin :  -0.05636930465698242   xmax :  1331.3785416666667   ymax :  120.151806640625\n",
      "frame : 114\n",
      "frame : 120\n",
      "frame : 126\n",
      "frame : 132\n",
      "frame : 138\n",
      "frame : 144\n",
      "frame : 150\n",
      "frame : 156\n",
      "frame : 162\n",
      "frame : 168\n",
      "frame : 174\n",
      "frame : 180\n",
      "frame : 186\n",
      "frame : 192\n",
      "frame : 198\n",
      "frame : 204\n",
      "xmin :  0.6658583879470825   ymin :  2.197909355163574   xmax :  1307.294305013021   ymax :  127.99669189453125\n",
      "frame : 210\n",
      "frame : 216\n",
      "frame : 222\n",
      "frame : 228\n",
      "frame : 234\n",
      "frame : 240\n",
      "frame : 246\n",
      "frame : 252\n",
      "frame : 258\n",
      "frame : 264\n",
      "frame : 270\n",
      "frame : 276\n",
      "frame : 282\n",
      "frame : 288\n",
      "frame : 294\n",
      "frame : 300\n",
      "frame : 306\n",
      "frame : 312\n",
      "frame : 318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n5. 방향 설정까지 했다면, 그 방향에서 edge가 몇 픽셀 떨어져 있는지를 재고, 각 skeleton line상의 pixel에 그 정보를 저장하자!\\n6. 거기서 max값을 return하자\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#영상의 경로를 지정하고 프레임 캡쳐\n",
    "#나중에는 비디오 캡쳐를 함과 동시에 input_images리스트에 곧바로 넣어버려서, 불필요한 이미지 입출력 과정을 줄이자\n",
    "#1초에 4프레임 캡쳐로 바꿈 (6프레임마다 저장)\n",
    "vidcap = cv2.VideoCapture('C:\\\\Users\\\\user\\Desktop\\\\video5.mp4')\n",
    "success,imagefile = vidcap.read()\n",
    "count = 0\n",
    "while success:\n",
    "    if(count%6==0):\n",
    "#프레임 캡쳐를 저장할 경로\n",
    "        cv2.imwrite(\"C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg\" % count, imagefile)    \n",
    "    success,imagefile = vidcap.read()\n",
    "    count += 1\n",
    "\n",
    "orig_images = [] \n",
    "input_images = [] \n",
    "\n",
    "# range는 추후 영상 플레이 타임 정보를 사용할 수 있도록 변경\n",
    "for i in range(0,320):\n",
    "    if(i%6==0):\n",
    "#프레임 캡쳐를 불러오는 경로\n",
    "        img_path = 'C:\\\\Users\\\\user\\Desktop\\\\frames\\\\frame%d.jpg'%i\n",
    "        #print(img_path)\n",
    "        orig_images.append(imread(img_path))\n",
    "        img = image.load_img(img_path, target_size=(img_height, img_width))\n",
    "        img = image.img_to_array(img)\n",
    "        img = np.array(img)\n",
    "        input_images.append(img)\n",
    "        \n",
    "input_images = np.array(input_images)\n",
    "orig_images = np.array(orig_images)\n",
    "\n",
    "num_of_frames = 16\n",
    "counting = 0\n",
    "saving_bounding_boxes = []\n",
    "\n",
    "print(\"Predicted boxes:\\n\")\n",
    "print('   class   conf xmin   ymin   xmax   ymax')\n",
    "\n",
    "# range는 추후 변수를 사용할 수 있도록 변경\n",
    "for i in range(0, 4):\n",
    "    y_pred = model.predict(input_images[i*num_of_frames:i*num_of_frames + num_of_frames])\n",
    "    confidence_threshold = 0.4\n",
    "\n",
    "    y_pred_thresh = [y_pred[k][y_pred[k,:,1] > confidence_threshold] for k in range(y_pred.shape[0])]\n",
    "    np.set_printoptions(precision=2, suppress=True, linewidth=90)\n",
    "\n",
    "    for j in range(0, num_of_frames):\n",
    "        print('frame :',counting)\n",
    "#        print(y_pred_thresh[j])\n",
    "        for box in y_pred_thresh[j]:\n",
    "            # Transform the predicted bounding boxes for the 300x300 image to the original image dimensions.\n",
    "            xmin = box[2] * orig_images[0].shape[1] / img_width\n",
    "            ymin = box[3] * orig_images[0].shape[0] / img_height\n",
    "            xmax = box[4] * orig_images[0].shape[1] / img_width\n",
    "            ymax = box[5] * orig_images[0].shape[0] / img_height\n",
    "            print('xmin : ',xmin, '  ymin : ',ymin, '  xmax : ',xmax, '  ymax : ',ymax)\n",
    "            # 균열이 탐지된 프레임과 b-box 정보가 saving_bounding_boxes <- 여기에 저장됨\n",
    "            saving_bounding_boxes.append([counting, xmin,ymin,xmax,ymax])\n",
    "        counting += 6\n",
    "        if(counting>320): break;\n",
    "            \n",
    "'''\n",
    "5. 방향 설정까지 했다면, 그 방향에서 edge가 몇 픽셀 떨어져 있는지를 재고, 각 skeleton line상의 pixel에 그 정보를 저장하자!\n",
    "6. 거기서 max값을 return하자\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 0 1303 107\n",
      "../../Desktop/test/0.jpg\n",
      "26 0 1307 108\n",
      "../../Desktop/test/1.jpg\n",
      "23 0 1305 108\n",
      "../../Desktop/test/2.jpg\n",
      "28 0 1306 108\n",
      "../../Desktop/test/3.jpg\n",
      "22 0 1308 111\n",
      "../../Desktop/test/4.jpg\n",
      "26 0 1310 111\n",
      "../../Desktop/test/5.jpg\n",
      "24 0 1302 110\n",
      "../../Desktop/test/6.jpg\n",
      "27 0 1302 108\n",
      "../../Desktop/test/7.jpg\n",
      "26 0 1301 107\n",
      "../../Desktop/test/8.jpg\n",
      "23 0 1304 112\n",
      "../../Desktop/test/9.jpg\n",
      "20 0 1300 110\n",
      "../../Desktop/test/10.jpg\n",
      "22 0 1299 108\n",
      "../../Desktop/test/11.jpg\n",
      "21 0 1301 109\n",
      "../../Desktop/test/12.jpg\n",
      "23 0 1303 110\n",
      "../../Desktop/test/13.jpg\n",
      "20 0 1295 106\n",
      "../../Desktop/test/14.jpg\n",
      "8 0 1295 111\n",
      "../../Desktop/test/15.jpg\n",
      "16 0 1306 112\n",
      "../../Desktop/test/16.jpg\n",
      "13 0 1331 120\n",
      "../../Desktop/test/18.jpg\n",
      "0 2 1307 127\n",
      "../../Desktop/test/34.jpg\n"
     ]
    }
   ],
   "source": [
    "from skimage import io\n",
    "\n",
    "cropped_frames = []\n",
    "\n",
    "for i in range(0, len(saving_bounding_boxes)):\n",
    "    frame_count = saving_bounding_boxes[i][0]//6\n",
    "    frame = orig_images[frame_count]\n",
    "    if(saving_bounding_boxes[i][1] < 0):\n",
    "        saving_bounding_boxes[i][1] = 0\n",
    "    xmin = int(saving_bounding_boxes[i][1])\n",
    "    if(saving_bounding_boxes[i][2] < 0):\n",
    "        saving_bounding_boxes[i][2] = 0\n",
    "    ymin = int(saving_bounding_boxes[i][2])\n",
    "    xmax = int(saving_bounding_boxes[i][3])\n",
    "    ymax = int(saving_bounding_boxes[i][4])\n",
    "    print(xmin,ymin,xmax,ymax)\n",
    "    cropped_frame = orig_images[frame_count][ymin:ymax, xmin:xmax, :]\n",
    "    cropped_frame = cropped_frame.astype('uint8')\n",
    "    img_path = '../../Desktop/test/%d.jpg'%frame_count\n",
    "    print(img_path)\n",
    "    cropped_frames.append(cropped_frame)\n",
    "    io.imsave(img_path, cropped_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\util\\arraycrop.py:177: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  cropped = ar[slices]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_time 1538145722.4002447\n",
      "--- 102.0319037437439 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# 1. Image binarization(Sauvola's method) using Pw and Pl, respectively\n",
    "# 오래 걸리는 문제가 있음\n",
    "\n",
    "import time\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "from skimage import data\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.data import page\n",
    "from skimage.filters import (threshold_sauvola)\n",
    "from PIL import Image\n",
    "\n",
    "start_time = time.time() \n",
    "matplotlib.rcParams['font.size'] = 9\n",
    "\n",
    "sauvola_frames_Pw_bw = []\n",
    "sauvola_frames_Pl_bw = []\n",
    "sauvola_frames_Pw = []\n",
    "sauvola_frames_Pl = []\n",
    "\n",
    "# Upload the image\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    img = cropped_frames[i]\n",
    "    img_gray = rgb2gray(img)\n",
    "\n",
    "    # 논문에선 각각 70,180이었으나 여기선 홀수 input만 가능\n",
    "    window_size_Pw = 71\n",
    "    window_size_Pl = 181\n",
    "    thresh_sauvola_Pw = threshold_sauvola(img_gray, window_size=window_size_Pw, k=0.42)\n",
    "    thresh_sauvola_Pl = threshold_sauvola(img_gray, window_size=window_size_Pl, k=0.18)\n",
    "\n",
    "    #Below are the converted images through Sauvola's method.\n",
    "    # _bw will contain 0 or 1, not true or false. bw means black or white.\n",
    "    binary_sauvola_Pw = img_gray > thresh_sauvola_Pw\n",
    "    binary_sauvola_Pl = img_gray > thresh_sauvola_Pl\n",
    "    binary_sauvola_Pw_bw = img_gray > thresh_sauvola_Pw\n",
    "    binary_sauvola_Pl_bw = img_gray > thresh_sauvola_Pl\n",
    "\n",
    "    binary_sauvola_Pw_bw.dtype = 'uint8'\n",
    "    binary_sauvola_Pl_bw.dtype = 'uint8'\n",
    "\n",
    "    binary_sauvola_Pw_bw *= 255\n",
    "    binary_sauvola_Pl_bw *= 255\n",
    "    \n",
    "    sauvola_frames_Pw_bw.append(binary_sauvola_Pw_bw)\n",
    "    sauvola_frames_Pl_bw.append(binary_sauvola_Pl_bw)\n",
    "    sauvola_frames_Pw.append(binary_sauvola_Pw)\n",
    "    sauvola_frames_Pl.append(binary_sauvola_Pl) \n",
    "    \n",
    "    img_path_Pw = '../../Desktop/Sauvola/Sauvola_Pw_%d.jpg'%i\n",
    "    img_path_Pl = '../../Desktop/Sauvola/Sauvola_Pl_%d.jpg'%i\n",
    "    \n",
    "    io.imsave(img_path_Pw, binary_sauvola_Pw_bw)\n",
    "    io.imsave(img_path_Pl, binary_sauvola_Pl_bw)\n",
    "\n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_1.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_3.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_4.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_5.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_15.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_16.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_17.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "c:\\users\\user\\anaconda2\\envs\\tensorflow-gpu\\lib\\site-packages\\skimage\\io\\_io.py:140: UserWarning: ../../Desktop/Skeleton/skeleton_Pw_18.jpg is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "# 2. Extract the skeletons of each images\n",
    "\n",
    "from skimage.morphology import skeletonize\n",
    "from skimage.util import invert\n",
    "\n",
    "skeleton_frames_Pw = []\n",
    "skeleton_frames_Pl = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "# Invert the binarized images\n",
    "    img_Pw = invert(sauvola_frames_Pw[i])\n",
    "    img_Pl = invert(sauvola_frames_Pl[i])\n",
    "\n",
    "    # Below are skeletonized images\n",
    "    skeleton_Pw = skeletonize(img_Pw)\n",
    "    skeleton_Pl = skeletonize(img_Pl)\n",
    "\n",
    "    # Convert true/false to 1/0 to save it as image\n",
    "    skeleton_Pw.dtype = 'uint8'\n",
    "    skeleton_Pl.dtype = 'uint8'\n",
    "\n",
    "    skeleton_Pw *= 255\n",
    "    skeleton_Pl *= 255\n",
    "\n",
    "    skeleton_frames_Pw.append(skeleton_Pw)\n",
    "    skeleton_frames_Pl.append(skeleton_Pl)   \n",
    "    \n",
    "    img_path_Pw = \"../../Desktop/Skeleton/skeleton_Pw_%d.jpg\"%i\n",
    "    img_path_Pl = \"../../Desktop/Skeleton/skeleton_Pl_%d.jpg\"%i\n",
    "    io.imsave(img_path_Pw, skeleton_Pw)\n",
    "    io.imsave(img_path_Pl, skeleton_Pl)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Detect the edges of each images\n",
    "### edge detection 할 때, 좋은 parameter를 찾아야 한다. 지금은 edge가 너무 두꺼움 (overestimation됨) ###\n",
    "import numpy as np\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import feature\n",
    "\n",
    "edges_frames_Pw = []\n",
    "edges_frames_Pl = []\n",
    "\n",
    "for i in range(0,len(cropped_frames)):\n",
    "    # Compute the Canny filter for two values of sigma\n",
    "    # canny(image, sigma=1.0, low_threshold=None, high_threshold=None, mask=None, use_quantiles=False)\n",
    "    # sigma가 1이었으나, 0.1로 조정하여 실제 균열 edge와 거의 같게 만듦.\n",
    "    # 정확도에서 문제가 생긴다면 1. skeleton의 방향 설정 방법을 바꾸던가, 2. 여기서 시그마 값을 살짝 늘리거나 줄여가면서 정확도를 테스트 해볼 것\n",
    "    edges_Pw = feature.canny(sauvola_frames_Pw[i], 0.09)\n",
    "    edges_Pl = feature.canny(sauvola_frames_Pl[i], 0.09)\n",
    "\n",
    "    edges_Pw.dtype = 'uint8'\n",
    "    edges_Pl.dtype = 'uint8'\n",
    "\n",
    "    edges_Pw *= 255\n",
    "    edges_Pl *= 255\n",
    "\n",
    "    edges_frames_Pw.append(edges_Pw)\n",
    "    edges_frames_Pl.append(edges_Pl)\n",
    "    \n",
    "    img_path_Pw = \"../../Desktop/edges/edges_Pw_%d.jpg\"%i\n",
    "    img_path_Pl = \"../../Desktop/edges/edges_Pl_%d.jpg\"%i\n",
    "    \n",
    "    io.imsave(img_path_Pw, edges_Pw)\n",
    "    io.imsave(img_path_Pl, edges_Pl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107, 1276)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 107 is out of bounds for axis 0 with size 107",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-b3022f650fd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m120\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m146\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskeleton_frames_Pw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_skeleton\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcrop_skeleton\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcrop_edges\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 107 is out of bounds for axis 0 with size 107"
     ]
    }
   ],
   "source": [
    "'''\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "print(skeleton_frames_Pw[0].shape)\n",
    "\n",
    "crop_skeleton = np.zeros((120,146))\n",
    "crop_edges = np.zeros((120,146))\n",
    "\n",
    "for i in range(0,120):\n",
    "    for j in range(0,146):\n",
    "        if(skeleton_frames_Pw[0][i][j] == 255): crop_skeleton[i][j] = crop_edges[i][j] = 1\n",
    "        else: crop_skeleton[i][j] = crop_edges[i][j] = 0\n",
    "        \n",
    "        \n",
    "np.savetxt(\"../../Desktop/skeleton.txt\", crop_skeleton, '%d')\n",
    "np.savetxt(\"../../Desktop/edge.txt\", crop_edges, '%d')\n",
    "\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in range(skeleton_frames_Pw[0].shape[0]):\n",
    "    for j in range(skeleton_frames_Pw[0].shape[1]):\n",
    "        if(skeleton_frames_Pw[0][i][j] == 255): count+=1\n",
    "            \n",
    "print(count)\n",
    "'''\n",
    "\n",
    "#edges_frames_Pw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Crack만이 detection되어서 넘어왔다는 가정이 있어야 함. 아니면 외부 배경 이미지도 균열 계산에 포함 됨\n",
    "\n",
    "import queue\n",
    "import math\n",
    "\n",
    "#5픽셀이 기준 or above\n",
    "dx_dir_right = [-5,-5,-5,-4,-3,-2,-1,0,1,2,3,4,5,5]\n",
    "dy_dir_right = [0,1,2,3,4,5,5,5,5,5,4,3,2,1]\n",
    "\n",
    "dx_dir_left = [5,5,5,4,3,2,1,0,-1,-2,-3,-4,-5,-5]\n",
    "dy_dir_left = [0,-1,-2,-3,-4,-5,-5,-5,-5,-5,-4,-3,-2,-1]\n",
    "\n",
    "dx_bfs = [-1,-1,0,1,1,1,0,-1]\n",
    "dy_bfs = [0,1,1,1,0,-1,-1,-1]\n",
    "\n",
    "start_time = time.time() \n",
    "\n",
    "for k in range(0,len(skeleton_frames_Pw)):\n",
    "    print('--------------',k,'-----------------')\n",
    "    start = [0,0]\n",
    "    next = []\n",
    "    q = queue.Queue()\n",
    "    q.put(start)\n",
    "\n",
    "    len_x = skeleton_frames_Pw[k].shape[0]\n",
    "    len_y = skeleton_frames_Pw[k].shape[1]\n",
    "\n",
    "    visit = np.zeros((len_x,len_y))\n",
    "    count = 0\n",
    "    crack_width_list = []\n",
    "\n",
    "    while(q.empty() == 0):\n",
    "        next = q.get()\n",
    "        x = next[0]\n",
    "        y = next[1]\n",
    "        right_x = right_y = left_x = left_y = -1\n",
    "\n",
    "\n",
    "        if(skeleton_frames_Pw[k][x][y] == 255):\n",
    "            for i in range(0, len(dx_dir_right)):\n",
    "                right_x = x + dx_dir_right[i]\n",
    "                right_y = y + dy_dir_right[i]\n",
    "                if(right_x<0 or right_y<0 or right_x>=len_x or right_y>=len_y): \n",
    "                    right_x = right_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][right_x][right_y] == 255): break;\n",
    "                if(i==13): right_x = right_y = -1\n",
    "\n",
    "            if(right_x == -1): \n",
    "                right_x = x\n",
    "                right_y = y\n",
    "\n",
    "            for i in range(0, len(dx_dir_left)):\n",
    "                left_x = x + dx_dir_left[i]\n",
    "                left_y = y + dy_dir_left[i]\n",
    "                if(left_x <0 or left_y<0 or left_x >=len_x or left_y>=len_y): \n",
    "                    left_x = left_y = -1\n",
    "                    continue;\n",
    "                if(skeleton_frames_Pw[k][left_x][left_y] == 255): break;\n",
    "                if(i==13): left_x = left_y = -1\n",
    "\n",
    "            if(left_x == -1): \n",
    "                left_x = x\n",
    "                left_y = y\n",
    "\n",
    "            base = right_y - left_y\n",
    "            height = right_x - left_x\n",
    "            hypotenuse = math.sqrt(base*base + height*height)\n",
    "\n",
    "            if(base==0 and height != 0): theta = 90.0\n",
    "            elif(base==0 and height == 0): continue\n",
    "            else: theta = math.degrees(math.acos((base * base + hypotenuse * hypotenuse - height * height)/(2.0 * base * hypotenuse)))\n",
    "\n",
    "\n",
    "\n",
    "            theta += 90\n",
    "            dist = 0\n",
    "\n",
    "            for i in range(0,2):\n",
    "\n",
    "\n",
    "                if(theta>360): theta -= 360\n",
    "                elif(theta<0): theta += 360    \n",
    "                #print(theta)\n",
    "                #print('x : ',x,'y : ',y)\n",
    "                pix_x=x\n",
    "                pix_y=y\n",
    "\n",
    "                #theta에러는 나중에 고치고\n",
    "                #모든 프레임을 처리하기 위한 루프 먼저 돌릴것\n",
    "                #결과 값을 UI와 연동하자\n",
    "\n",
    "                if(theta>0 and theta<90):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((x - pix_x + 1)/(pix_y - y + 1)> ratio): pix_y+=1\n",
    "                        else: pix_x-=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta>90 and theta<180):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((x - pix_x + 1)/(y - pix_y + 1)> ratio): pix_y-=1\n",
    "                        else: pix_x-=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta>180 and theta<270):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((pix_x - x + 1)/(y - pix_y+ 1)> ratio): pix_y-=1\n",
    "                        else: pix_x+=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;     \n",
    "\n",
    "                elif(theta>270 and theta<360):\n",
    "                    ratio = abs(math.tan(theta))\n",
    "                    while(1):\n",
    "                        if((pix_x - x + 1)/(pix_y - y + 1)> ratio): pix_y+=1\n",
    "                        else: pix_x+=1\n",
    "\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 0.0 or 360.0):\n",
    "                     while(1):\n",
    "                        pix_y+=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 90.0):\n",
    "                    while(1):\n",
    "                        pix_x-=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 180.0):\n",
    "                    while(1):\n",
    "                        pix_y-=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;\n",
    "\n",
    "                elif(theta == 270.0):\n",
    "                     while(1):\n",
    "                        pix_x+=1\n",
    "                        if(pix_x<0 or pix_y<0 or pix_x>=len_x or pix_y>=len_y):\n",
    "                            pix_x = x\n",
    "                            pix_y = y\n",
    "                            break;\n",
    "                        if(edges_frames_Pw[k][pix_x][pix_y]==255): break;            \n",
    "\n",
    "                dist += math.sqrt((y-pix_y)**2 + (x-pix_x)**2)\n",
    "                theta += 180        \n",
    "\n",
    "                #print('pix_x : ',pix_x,'pix_y : ',pix_y,'dist : ', dist,'\\n')\n",
    "\n",
    "            crack_width_list.append(dist)\n",
    "        \n",
    "            #해당 위치와 균열 폭을 힘께 저장하는 새로운 리스트 사용하기\n",
    "        for i in range(0,8):\n",
    "            next_x = x + dx_bfs[i]\n",
    "            next_y = y + dy_bfs[i]\n",
    "\n",
    "            if(next_x<0 or next_y<0 or next_x>=len_x or next_y>=len_y): continue;\n",
    "            if(visit[next_x][next_y] == 0): \n",
    "                q.put([next_x,next_y])\n",
    "                visit[next_x][next_y] = 1\n",
    "        \n",
    "    print(max(crack_width_list))\n",
    "        \n",
    "print(\"start_time\", start_time)\n",
    "print(\"--- %s seconds ---\" %(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
